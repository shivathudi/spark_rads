{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip this cell if you already have a chunk of the transactions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/transactions.csv'\n",
    "chunksize = 10 ** 5\n",
    "chunk_iter = pd.read_csv(file_name, chunksize=chunksize)\n",
    "chunk1 = chunk_iter.next()\n",
    "chunk1.to_csv('../data/transactions_chunk1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile('../data/transactions_chunk1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = lines.first()\n",
    "lines = lines.filter(lambda row: row != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for parsing the strings from the CSV file\n",
    "\n",
    "def toIntSafe(inval):\n",
    "  try:\n",
    "    return int(inval)\n",
    "  except ValueError:\n",
    "    return None\n",
    "\n",
    "def toTimeSafe(inval):\n",
    "  try:\n",
    "    return datetime.strptime(inval, \"%Y-%m-%d\")\n",
    "  except ValueError:\n",
    "    return None\n",
    "\n",
    "def toLongSafe(inval):\n",
    "  try:\n",
    "    return long(inval)\n",
    "  except ValueError:\n",
    "    return None\n",
    "\n",
    "def toFloatSafe(inval):\n",
    "  try:\n",
    "    return float(inval)\n",
    "  except ValueError:\n",
    "    return None\n",
    "    \n",
    "def stringToPost(row):\n",
    "  r = row.encode('utf8').split(',')\n",
    "  return Row(\n",
    "    int(r[0]),         # Don't want this column to be nullable\n",
    "    toLongSafe(r[1]),\n",
    "    toLongSafe(r[2]),\n",
    "    toLongSafe(r[3]),\n",
    "    toLongSafe(r[4]),\n",
    "    toLongSafe(r[5]),\n",
    "    toTimeSafe(r[6]),\n",
    "    toFloatSafe(r[7]),\n",
    "    r[8],\n",
    "    toLongSafe(r[9]),\n",
    "    toFloatSafe(r[10]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"chain\", LongType(), True),\n",
    "    StructField(\"dept\", LongType(), True),\n",
    "    StructField(\"category\", LongType(), True),\n",
    "    StructField(\"company\", LongType(), True),\n",
    "    StructField(\"brand\", LongType(), True),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"productsize\", DoubleType(), True),\n",
    "    StructField(\"purchasemeasure\", StringType(), True),\n",
    "    StructField(\"purchasequantity\", LongType(), True),\n",
    "    StructField(\"purchaseamount\", DoubleType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowRDD = lines.map(lambda p: stringToPost(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions = sqlContext.createDataFrame(rowRDD, transactions_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- chain: long (nullable = true)\n",
      " |-- dept: long (nullable = true)\n",
      " |-- category: long (nullable = true)\n",
      " |-- company: long (nullable = true)\n",
      " |-- brand: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- productsize: double (nullable = true)\n",
      " |-- purchasemeasure: string (nullable = true)\n",
      " |-- purchasequantity: long (nullable = true)\n",
      " |-- purchaseamount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+--------+----------+-----+----------+-----------+---------------+----------------+--------------+\n",
      "|   id|chain|dept|category|   company|brand|      date|productsize|purchasemeasure|purchasequantity|purchaseamount|\n",
      "+-----+-----+----+--------+----------+-----+----------+-----------+---------------+----------------+--------------+\n",
      "|86246|  205|   7|     707|1078778070|12564|2012-03-02|       12.0|             OZ|               1|          7.59|\n",
      "|86246|  205|  63|    6319| 107654575|17876|2012-03-02|       64.0|             OZ|               1|          1.59|\n",
      "|86246|  205|  97|    9753|1022027929|    0|2012-03-02|        1.0|             CT|               1|          5.99|\n",
      "|86246|  205|  25|    2509| 107996777|31373|2012-03-02|       16.0|             OZ|               1|          1.99|\n",
      "|86246|  205|  55|    5555| 107684070|32094|2012-03-02|       16.0|             OZ|               2|         10.38|\n",
      "|86246|  205|  97|    9753|1021015020|    0|2012-03-02|        1.0|             CT|               1|           7.8|\n",
      "|86246|  205|  99|    9909| 104538848|15343|2012-03-02|       16.0|             OZ|               1|          2.49|\n",
      "|86246|  205|  59|    5907| 102900020| 2012|2012-03-02|       16.0|             OZ|               1|          1.39|\n",
      "|86246|  205|   9|     921| 101128414| 9209|2012-03-02|        4.0|             OZ|               2|           1.5|\n",
      "|86246|  205|  73|    7344|1068142161|20285|2012-03-02|        8.0|             CT|               1|          5.79|\n",
      "|86246|  205|  41|    4107| 104113040|28204|2012-03-02|       14.5|             OZ|               1|          0.59|\n",
      "|86246|  205|  21|    2106| 105100050|27873|2012-03-02|       64.0|             OZ|               1|          3.29|\n",
      "|86246|  205|   8|     814| 102840020|18584|2012-03-02|       15.5|             OZ|               1|          3.29|\n",
      "|86246|  205|  91|    9122| 108200080| 2911|2012-03-02|       10.0|             OZ|               1|          1.99|\n",
      "|86246|  205|  41|    4120| 101116616|15266|2012-03-02|        6.0|             OZ|               1|          0.89|\n",
      "|86246|  205|  63|    6315| 107996777|31373|2012-03-02|       64.0|             OZ|               1|          3.59|\n",
      "|86246|  205|   9|     907| 101410010|13791|2012-03-02|       24.0|             OZ|               1|          3.99|\n",
      "|86246|  205|  97|    9753|1021013323|    0|2012-03-02|        1.0|             CT|               1|          8.87|\n",
      "|86246|  205|  45|    4509|1082650484|59628|2012-03-02|       16.0|             OZ|               1|          4.99|\n",
      "|86246|  205|  26|    2630| 103700030|14647|2012-03-02|       56.0|             CT|               1|           1.0|\n",
      "+-----+-----+----+--------+----------+-----+----------+-----------+---------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of refund transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+\n",
      "|      id|total_trans|total_returns|\n",
      "+--------+-----------+-------------+\n",
      "|18470775|        350|            8|\n",
      "|14723452|        755|            5|\n",
      "|15738658|         39|            0|\n",
      "|17552659|        591|            4|\n",
      "|12996040|        326|            5|\n",
      "|16078766|        966|           54|\n",
      "|18249735|       1557|           60|\n",
      "|14989775|        614|           39|\n",
      "|15073302|        526|           38|\n",
      "|16075389|        591|           32|\n",
      "|16606739|        678|            6|\n",
      "|15705695|        431|            8|\n",
      "|14576147|        817|           66|\n",
      "|15134033|        944|           13|\n",
      "|16551772|       1699|           47|\n",
      "|17652157|       1407|           15|\n",
      "|13089312|       1218|           52|\n",
      "|13744500|       2232|          112|\n",
      "|16829614|        738|           10|\n",
      "|17524817|        328|            7|\n",
      "+--------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "returns = transactions.select('id',\n",
    "                              F.when(transactions['purchaseamount'] < 0, 1).otherwise(0).alias('return'))\\\n",
    "                      .withColumn('1', F.lit(1))\n",
    "returns = returns.groupBy('id').agg(F.sum('1').alias('total_trans'), F.sum(\"return\").alias('total_returns'))\n",
    "returns.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/trainHistory.csv')\n",
    "offers = pd.read_csv('../data/offers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add department to offers\n",
    "dept = []\n",
    "for i in range(offers.shape[0]):\n",
    "    str_category = str(offers['category'].iloc[i])\n",
    "    if len(str_category) == 4:\n",
    "        dept.append(str_category[:2])\n",
    "    else:\n",
    "        dept.append(str_category[:1])\n",
    "        \n",
    "offers['dept'] = dept\n",
    "offers['dept'] = pd.to_numeric(offers['dept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, offers, how='left', on=['offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "train.columns = ['id', 'chain', 'offer', 'market', 'repeattrips', 'repeater', 'offerdate', \n",
    "                 'offer_category', 'quantity', 'offer_company', 'offervalue', 'offer_brand',\n",
    "                 'offer_dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reencode the target variable\n",
    "train['repeater'] = np.where(train['repeater'] == 't', '1', '0')\n",
    "train['repeater'] = pd.to_numeric(train['repeater'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['offerdate'] = train['offerdate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/testHistory.csv')\n",
    "test = pd.merge(test, offers, how='left', on=['offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "test.columns = ['id', 'chain', 'offer', 'market', 'offerdate', 'offer_category', 'quantity', \n",
    "                'offer_company', 'offervalue', 'offer_brand', 'offer_dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['offerdate'] = test['offerdate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"offer_chain\", LongType(), True),\n",
    "    StructField(\"offer\", LongType(), True),\n",
    "    StructField(\"market\", LongType(), True),\n",
    "    StructField(\"repeattrips\", LongType(), True),\n",
    "    StructField(\"repeater\", IntegerType(), True),\n",
    "    StructField(\"offerdate\", StringType(), True),\n",
    "    StructField(\"offer_category\", LongType(), True),\n",
    "    StructField(\"quantity\", LongType(), True),\n",
    "    StructField(\"offer_company\", LongType(), True),\n",
    "    StructField(\"offervalue\", DoubleType(), True),\n",
    "    StructField(\"offer_brand\", LongType(), True),\n",
    "    StructField(\"offer_dept\", LongType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = sqlContext.createDataFrame(train, train_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"offer_chain\", LongType(), True),\n",
    "    StructField(\"offer\", LongType(), True),\n",
    "    StructField(\"market\", LongType(), True),\n",
    "    StructField(\"offerdate\", StringType(), True),\n",
    "    StructField(\"offer_category\", LongType(), True),\n",
    "    StructField(\"quantity\", LongType(), True),\n",
    "    StructField(\"offer_company\", LongType(), True),\n",
    "    StructField(\"offervalue\", DoubleType(), True),\n",
    "    StructField(\"offer_brand\", LongType(), True),\n",
    "    StructField(\"offer_dept\", LongType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = sqlContext.createDataFrame(test, test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function converts the string cell into a date:\n",
    "stringToDate = F.udf(lambda x: datetime.strptime(x, '%Y-%m-%d'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert offerdate to date type\n",
    "train_df = train_df.withColumn('offerdate', stringToDate(F.col('offerdate')))\n",
    "test_df = test_df.withColumn('offerdate', stringToDate(F.col('offerdate')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.withColumnRenamed('repeater', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.select('offer', 'label')\n",
    "test_df = test_df.select('offer', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[offer: bigint, id: bigint]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert offers to numerical categories\n",
    "offer_df = train_df.select('offer').union(test_df.select('offer'))\n",
    "indexer = StringIndexer().setInputCol(\"offer\").setOutputCol(\"offer_idx\").fit(offer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot-encoding of offer category\n",
    "encoder = OneHotEncoder().setInputCol(\"offer_idx\").setOutputCol(\"encoded\").setDropLast(False)\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=[\"encoded\"], outputCol=\"features\")\n",
    "\n",
    "# Logistic regression\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularization = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "kfolds = 2\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, regularization) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=kfolds)  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.379723348063,0.0,0.0,0.0,0.768400355884,0.283072854182,0.724445673384,0.0,-1.49917011788,0.110476732692,0.0,0.533731203239,-1.09835919751,1.06045507859,-0.756703541547,0.0,0.0,0.207779814063,0.0,0.0,0.373975661609,0.0,-1.34356821348,-0.581562602664,0.0,-0.501814726175,-0.361011872975,-0.267339230459,0.0,0.0,-0.616881052971,-0.442098418788,-0.578534610908,-1.10035450515,-0.394207437488,-0.291895038351,-0.177066153567]\n",
      "Intercept: -1.03268048499\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(cvModel.bestModel.stages[3].coefficients))\n",
    "print(\"Intercept: \" + str(cvModel.bestModel.stages[3].intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred = cvModel.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         probability|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.67909319788162...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.83399965024132...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.85685173976960...|       0.0|\n",
      "|[0.85685173976960...|       0.0|\n",
      "|[0.71549092254498...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.85685173976960...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.67909319788162...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "|[0.80414481437532...|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred.select('probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = cvModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         probability|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "|[0.73743523364202...|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.select('probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_id = test_df.select('id').toPandas()\n",
    "test_prob = test_pred.select('probability').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I didn't know how to access the vector inside the probability column.\n",
    "# To work around this, I looped through the probability column and used the indexing operations to pull out\n",
    "# the individual probabilities.\n",
    "prob = []\n",
    "for i in range(test_prob.shape[0]):\n",
    "    prob.append(test_prob['probability'][i][1])\n",
    "test_prob['probYes'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_final_pred = pd.merge(test_id, test_prob, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "      <th>probYes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12262064</td>\n",
       "      <td>[0.737435233642, 0.262564766358]</td>\n",
       "      <td>0.262565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12277270</td>\n",
       "      <td>[0.737435233642, 0.262564766358]</td>\n",
       "      <td>0.262565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12332190</td>\n",
       "      <td>[0.737435233642, 0.262564766358]</td>\n",
       "      <td>0.262565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12524696</td>\n",
       "      <td>[0.737435233642, 0.262564766358]</td>\n",
       "      <td>0.262565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13074629</td>\n",
       "      <td>[0.737435233642, 0.262564766358]</td>\n",
       "      <td>0.262565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                       probability   probYes\n",
       "0  12262064  [0.737435233642, 0.262564766358]  0.262565\n",
       "1  12277270  [0.737435233642, 0.262564766358]  0.262565\n",
       "2  12332190  [0.737435233642, 0.262564766358]  0.262565\n",
       "3  12524696  [0.737435233642, 0.262564766358]  0.262565\n",
       "4  13074629  [0.737435233642, 0.262564766358]  0.262565"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151484.000000\n",
       "mean          0.262785\n",
       "std           0.018394\n",
       "min           0.143148\n",
       "25%           0.262565\n",
       "50%           0.262565\n",
       "75%           0.262565\n",
       "max           0.434312\n",
       "Name: probYes, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_pred['probYes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
