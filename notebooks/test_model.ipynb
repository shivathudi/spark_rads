{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip this cell if you already have a chunk of the transactions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/transactions.csv'\n",
    "chunksize = 10 ** 5\n",
    "chunk_iter = pd.read_csv(file_name, chunksize=chunksize)\n",
    "chunk1 = chunk_iter.next()\n",
    "chunk1.to_csv('../data/transactions_chunk1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile('../data/transactions_chunk1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = lines.first()\n",
    "lines = lines.filter(lambda row: row != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for parsing the strings from the CSV file\n",
    "\n",
    "def toIntSafe(inval):\n",
    "  try:\n",
    "    return int(inval)\n",
    "  except ValueError:\n",
    "    return None\n",
    "\n",
    "def toTimeSafe(inval):\n",
    "  try:\n",
    "    return datetime.strptime(inval, \"%Y-%m-%d\")\n",
    "  except ValueError:\n",
    "    return None\n",
    "\n",
    "def toLongSafe(inval):\n",
    "  try:\n",
    "    return long(inval)\n",
    "  except ValueError:\n",
    "    return None\n",
    "\n",
    "def toFloatSafe(inval):\n",
    "  try:\n",
    "    return float(inval)\n",
    "  except ValueError:\n",
    "    return None\n",
    "    \n",
    "def stringToPost(row):\n",
    "  r = row.encode('utf8').split(',')\n",
    "  return Row(\n",
    "    int(r[0]),         # Don't want this column to be nullable\n",
    "    toLongSafe(r[1]),\n",
    "    toLongSafe(r[2]),\n",
    "    toLongSafe(r[3]),\n",
    "    toLongSafe(r[4]),\n",
    "    toLongSafe(r[5]),\n",
    "    toTimeSafe(r[6]),\n",
    "    toFloatSafe(r[7]),\n",
    "    r[8],\n",
    "    toLongSafe(r[9]),\n",
    "    toFloatSafe(r[10]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"chain\", LongType(), True),\n",
    "    StructField(\"dept\", LongType(), True),\n",
    "    StructField(\"category\", LongType(), True),\n",
    "    StructField(\"company\", LongType(), True),\n",
    "    StructField(\"brand\", LongType(), True),\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"productsize\", DoubleType(), True),\n",
    "    StructField(\"purchasemeasure\", StringType(), True),\n",
    "    StructField(\"purchasequantity\", LongType(), True),\n",
    "    StructField(\"purchaseamount\", DoubleType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowRDD = lines.map(lambda p: stringToPost(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions = sqlContext.createDataFrame(rowRDD, transactions_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- chain: long (nullable = true)\n",
      " |-- dept: long (nullable = true)\n",
      " |-- category: long (nullable = true)\n",
      " |-- company: long (nullable = true)\n",
      " |-- brand: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- productsize: double (nullable = true)\n",
      " |-- purchasemeasure: string (nullable = true)\n",
      " |-- purchasequantity: long (nullable = true)\n",
      " |-- purchaseamount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+--------+----------+-----+----------+-----------+---------------+----------------+--------------+\n",
      "|   id|chain|dept|category|   company|brand|      date|productsize|purchasemeasure|purchasequantity|purchaseamount|\n",
      "+-----+-----+----+--------+----------+-----+----------+-----------+---------------+----------------+--------------+\n",
      "|86246|  205|   7|     707|1078778070|12564|2012-03-02|       12.0|             OZ|               1|          7.59|\n",
      "|86246|  205|  63|    6319| 107654575|17876|2012-03-02|       64.0|             OZ|               1|          1.59|\n",
      "|86246|  205|  97|    9753|1022027929|    0|2012-03-02|        1.0|             CT|               1|          5.99|\n",
      "|86246|  205|  25|    2509| 107996777|31373|2012-03-02|       16.0|             OZ|               1|          1.99|\n",
      "|86246|  205|  55|    5555| 107684070|32094|2012-03-02|       16.0|             OZ|               2|         10.38|\n",
      "|86246|  205|  97|    9753|1021015020|    0|2012-03-02|        1.0|             CT|               1|           7.8|\n",
      "|86246|  205|  99|    9909| 104538848|15343|2012-03-02|       16.0|             OZ|               1|          2.49|\n",
      "|86246|  205|  59|    5907| 102900020| 2012|2012-03-02|       16.0|             OZ|               1|          1.39|\n",
      "|86246|  205|   9|     921| 101128414| 9209|2012-03-02|        4.0|             OZ|               2|           1.5|\n",
      "|86246|  205|  73|    7344|1068142161|20285|2012-03-02|        8.0|             CT|               1|          5.79|\n",
      "|86246|  205|  41|    4107| 104113040|28204|2012-03-02|       14.5|             OZ|               1|          0.59|\n",
      "|86246|  205|  21|    2106| 105100050|27873|2012-03-02|       64.0|             OZ|               1|          3.29|\n",
      "|86246|  205|   8|     814| 102840020|18584|2012-03-02|       15.5|             OZ|               1|          3.29|\n",
      "|86246|  205|  91|    9122| 108200080| 2911|2012-03-02|       10.0|             OZ|               1|          1.99|\n",
      "|86246|  205|  41|    4120| 101116616|15266|2012-03-02|        6.0|             OZ|               1|          0.89|\n",
      "|86246|  205|  63|    6315| 107996777|31373|2012-03-02|       64.0|             OZ|               1|          3.59|\n",
      "|86246|  205|   9|     907| 101410010|13791|2012-03-02|       24.0|             OZ|               1|          3.99|\n",
      "|86246|  205|  97|    9753|1021013323|    0|2012-03-02|        1.0|             CT|               1|          8.87|\n",
      "|86246|  205|  45|    4509|1082650484|59628|2012-03-02|       16.0|             OZ|               1|          4.99|\n",
      "|86246|  205|  26|    2630| 103700030|14647|2012-03-02|       56.0|             CT|               1|           1.0|\n",
      "+-----+-----+----+--------+----------+-----+----------+-----------+---------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/trainHistory.csv')\n",
    "offers = pd.read_csv('../data/offers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add department to offers\n",
    "dept = []\n",
    "for i in range(offers.shape[0]):\n",
    "    str_category = str(offers['category'].iloc[i])\n",
    "    if len(str_category) == 4:\n",
    "        dept.append(str_category[:2])\n",
    "    else:\n",
    "        dept.append(str_category[:1])\n",
    "        \n",
    "offers['dept'] = dept\n",
    "offers['dept'] = pd.to_numeric(offers['dept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, offers, how='left', on=['offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "train.columns = ['id', 'chain', 'offer', 'market', 'repeattrips', 'repeater', 'offerdate', \n",
    "                 'offer_category', 'quantity', 'offer_company', 'offervalue', 'offer_brand',\n",
    "                 'offer_dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reencode the target variable\n",
    "train['repeater'] = np.where(train['repeater'] == 't', '1', '0')\n",
    "train['repeater'] = pd.to_numeric(train['repeater'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['offerdate'] = train['offerdate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"offer_chain\", LongType(), True),\n",
    "    StructField(\"offer\", LongType(), True),\n",
    "    StructField(\"market\", LongType(), True),\n",
    "    StructField(\"repeattrips\", LongType(), True),\n",
    "    StructField(\"repeater\", IntegerType(), True),\n",
    "    StructField(\"offerdate\", StringType(), True),\n",
    "    StructField(\"offer_category\", LongType(), True),\n",
    "    StructField(\"quantity\", LongType(), True),\n",
    "    StructField(\"offer_company\", LongType(), True),\n",
    "    StructField(\"offervalue\", DoubleType(), True),\n",
    "    StructField(\"offer_brand\", LongType(), True),\n",
    "    StructField(\"offer_dept\", LongType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = sqlContext.createDataFrame(train, train_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/testHistory.csv')\n",
    "test = pd.merge(test, offers, how='left', on=['offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "test.columns = ['id', 'chain', 'offer', 'market', 'offerdate', 'offer_category', 'quantity', \n",
    "                'offer_company', 'offervalue', 'offer_brand', 'offer_dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['offerdate'] = test['offerdate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_schema = StructType([\n",
    "    StructField(\"id\", LongType(), False),\n",
    "    StructField(\"offer_chain\", LongType(), True),\n",
    "    StructField(\"offer\", LongType(), True),\n",
    "    StructField(\"market\", LongType(), True),\n",
    "    StructField(\"offerdate\", StringType(), True),\n",
    "    StructField(\"offer_category\", LongType(), True),\n",
    "    StructField(\"quantity\", LongType(), True),\n",
    "    StructField(\"offer_company\", LongType(), True),\n",
    "    StructField(\"offervalue\", DoubleType(), True),\n",
    "    StructField(\"offer_brand\", LongType(), True),\n",
    "    StructField(\"offer_dept\", LongType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = sqlContext.createDataFrame(test, test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function converts the string cell into a date:\n",
    "stringToDate = F.udf(lambda x: datetime.strptime(x, '%Y-%m-%d'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert offerdate to date type\n",
    "train_df = train_df.withColumn('offerdate', stringToDate(F.col('offerdate')))\n",
    "test_df = test_df.withColumn('offerdate', stringToDate(F.col('offerdate')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.withColumnRenamed('repeater', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get number of refund transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+--------------------+------------------+\n",
      "|      id|total_trans|total_returns|avg_purchasequantity|avg_purchaseamount|\n",
      "+--------+-----------+-------------+--------------------+------------------+\n",
      "|18470775|        350|            8|                1.34|3.1511428571428635|\n",
      "|14723452|        755|            5|  1.2264900662251657| 4.073933774834406|\n",
      "|15738658|         39|            0|   1.205128205128205| 4.780000000000001|\n",
      "|17552659|        591|            4|  1.5245346869712353| 4.931455160744474|\n",
      "|12996040|        326|            5|  1.2331288343558282|4.7280981595092095|\n",
      "|16078766|        966|           54|   1.818840579710145| 5.298498964803263|\n",
      "|18249735|       1557|           60|  1.2594733461785486|  4.13752087347458|\n",
      "|14989775|        614|           39|   1.231270358306189|3.8022475570032475|\n",
      "|15073302|        526|           38|  1.3669201520912548| 4.640133079847899|\n",
      "|16075389|        591|           32|  1.9593908629441625| 7.553604060913664|\n",
      "|16606739|        678|            6|  1.2905604719764012|5.6328908554571955|\n",
      "|15705695|        431|            8|   1.357308584686775| 5.145730858468677|\n",
      "|14576147|        817|           66|  1.5960832313341493| 3.623157894736831|\n",
      "|15134033|        944|           13|  1.7997881355932204| 5.452923728813514|\n",
      "|16551772|       1699|           47|  1.4096527369040612| 4.735797527957543|\n",
      "|17652157|       1407|           15|  1.2224591329068941| 4.885799573560684|\n",
      "|13089312|       1218|           52|  1.2060755336617406| 3.194318555008175|\n",
      "|13744500|       2232|          112|   1.260304659498208| 4.279466845878071|\n",
      "|16829614|        738|           10|  1.2357723577235773|3.0218834688346874|\n",
      "|17524817|        328|            7|  1.3567073170731707|3.6432926829268335|\n",
      "+--------+-----------+-------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_stats = transactions.select('id', 'purchasequantity', 'purchaseamount',\n",
    "                              F.when(transactions['purchaseamount'] < 0, 1).otherwise(0).alias('return'))\\\n",
    "                      .withColumn('1', F.lit(1))\n",
    "id_stats = id_stats.groupBy('id').agg(F.sum('1').alias('total_trans'), \n",
    "                                      F.sum('return').alias('total_returns'),\n",
    "                                      F.avg('purchasequantity').alias('avg_purchasequantity'),\n",
    "                                      F.avg('purchaseamount').alias('avg_purchaseamount'))\n",
    "id_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename id column of returns table to avoid ambiguous column names\n",
    "id_stats = id_stats.withColumnRenamed('id', 'returns_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.join(id_stats, train_df['id'] == id_stats['returns_id'], 'left')\n",
    "test_df = test_df.join(id_stats, test_df['id'] == id_stats['returns_id'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.select('offer', 'offer_category', 'offer_brand', 'offer_company', 'offervalue', \n",
    "                           'total_trans', 'total_returns', 'avg_purchasequantity', 'avg_purchaseamount', 'label')\n",
    "test_df = test_df.select('offer', 'offer_category', 'offer_brand', 'offer_company', 'offervalue', \n",
    "                         'total_trans', 'total_returns', 'avg_purchasequantity', 'avg_purchaseamount', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get average value for imputations\n",
    "avg_total_trans = id_stats.agg(F.avg(F.col('total_trans'))).first()[0]\n",
    "avg_total_returns = id_stats.agg(F.avg(F.col('total_returns'))).first()[0]\n",
    "avg_avg_purchasequantity = id_stats.agg(F.avg(F.col('avg_purchasequantity'))).first()[0]\n",
    "avg_avg_purchaseamount = id_stats.agg(F.avg(F.col('avg_purchaseamount'))).first()[0]\n",
    "\n",
    "# Impute missing data\n",
    "impute_dict = {'total_trans': avg_total_trans, 'total_returns': avg_total_returns,\n",
    "               'avg_purchasequantity': avg_avg_purchasequantity,\n",
    "               'avg_purchaseamount': avg_avg_purchaseamount}\n",
    "train_df = train_df.fillna(impute_dict)\n",
    "test_df = test_df.fillna(impute_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the offers, categories, brands and companies from both training and test\n",
    "# Then create a StringIndexer to map categorical values to numeric labels\n",
    "cols_to_index = ['offer', 'offer_category', 'offer_brand', 'offer_company']\n",
    "indexers = []\n",
    "for col in cols_to_index:\n",
    "    union_df = train_df.select(col).union(test_df.select(col))\n",
    "    indexers.append(StringIndexer().setInputCol(col).setOutputCol(col+'idx').fit(union_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One-hot-encoding of categorical variables\n",
    "encoders = []\n",
    "for col in cols_to_index:\n",
    "    encoders.append(OneHotEncoder().setInputCol(col+'idx').setOutputCol(col+'_encoded').setDropLast(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assemble features\n",
    "inputCols = ['offervalue', 'offer_encoded', 'offer_category_encoded', 'offer_brand_encoded', 'offer_company_encoded', \n",
    "             'total_trans', 'total_returns', 'avg_purchasequantity', 'avg_purchaseamount']\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression(maxIter=10, standardization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "stages = indexers + encoders + [assembler, lr]\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularization = [0.0001, 0.001]   # for testing purposes\n",
    "#regularization = [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "kfolds = 2\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, regularization) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=kfolds)  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[offer: bigint, offer_category: bigint, offer_brand: bigint, offer_company: bigint, offervalue: double, total_trans: bigint, total_returns: bigint, avg_purchasequantity: double, avg_purchaseamount: double, id: bigint]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.0429443394893,-0.120828064549,0.0,0.0,0.0,0.211433225354,0.0637029341056,0.192683530963,0.0,-0.240026654901,0.0160405151517,0.0,0.127899969392,-0.198888647052,0.282359546423,-0.152730849875,0.0,0.0,0.0399239681762,0.0,0.0,0.081020743848,0.0,-0.219622642058,-0.123039556646,0.0,-0.109590355519,-0.0843160148191,-0.0661700731342,0.0,0.0,-0.127940962218,-0.0986583139025,-0.121933421527,-0.192675565725,-0.0899414243517,-0.0705857787871,-0.0473126533044,0.0,-0.120828064549,0.0,0.23650271708,0.211433225354,0.0613482528862,-0.232047234628,0.0,0.0,0.117857839674,0.0160405151517,-0.0873028040284,-0.149545108453,-0.118094349399,0.0,-0.213903048893,0.0,0.0,-0.0986583139025,-0.0473126533044,0.0,-0.120828064549,0.0,0.211433225354,0.0613482528862,0.192683530963,-0.232047234628,0.0,0.0,-0.178737903433,0.117857839674,0.0160405151517,-0.0873028040284,0.282359546423,-0.118094349399,0.0,0.0,0.0,-0.0986583139025,0.0,-0.120828064549,-0.0329635068416,0.0,0.211433225354,0.192683530963,-0.232047234628,0.0,0.0,0.117857839674,0.0160405151517,-0.0873028040284,0.282359546423,-0.118094349399,0.0,0.0,0.0,-0.0986583139025,7.62383278548e-05,-0.00163746313466,-0.296599567152,0.0746541462949]\n",
      "Intercept: -0.987578511662\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(cvModel.bestModel.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(cvModel.bestModel.stages[-1].intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred = cvModel.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         probability|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.72003434577649...|       0.0|\n",
      "|[0.72003434577649...|       0.0|\n",
      "|[0.73328529723190...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.72003434577649...|       0.0|\n",
      "|[0.72927779755293...|       0.0|\n",
      "|[0.82918143595882...|       0.0|\n",
      "|[0.82918143595882...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "|[0.82353291521212...|       0.0|\n",
      "|[0.82166951058277...|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred.select('probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = cvModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         probability|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.76479254131548...|       0.0|\n",
      "|[0.75786544152271...|       0.0|\n",
      "|[0.77327570477242...|       0.0|\n",
      "|[0.74584921916645...|       0.0|\n",
      "|[0.74175755178399...|       0.0|\n",
      "|[0.74584921916645...|       0.0|\n",
      "|[0.74989791590015...|       0.0|\n",
      "|[0.74175755178399...|       0.0|\n",
      "|[0.75786544152271...|       0.0|\n",
      "|[0.75786544152271...|       0.0|\n",
      "|[0.74989791590015...|       0.0|\n",
      "|[0.75786544152271...|       0.0|\n",
      "|[0.74584921916645...|       0.0|\n",
      "|[0.74584921916645...|       0.0|\n",
      "|[0.74584921916645...|       0.0|\n",
      "|[0.74989791590015...|       0.0|\n",
      "|[0.77327570477242...|       0.0|\n",
      "|[0.74989791590015...|       0.0|\n",
      "|[0.74584921916645...|       0.0|\n",
      "|[0.75786544152271...|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred.select('probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_id = test_df.select('id').toPandas()\n",
    "test_prob = test_pred.select('probability').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I didn't know how to access the vector inside the probability column.\n",
    "# To work around this, I looped through the probability column and used the indexing operations to pull out\n",
    "# the individual probabilities.\n",
    "prob = []\n",
    "for i in range(test_prob.shape[0]):\n",
    "    prob.append(test_prob['probability'][i][1])\n",
    "test_prob['repeatProbability'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_final_pred = pd.merge(test_id, test_prob, left_index=True, right_index=True)\n",
    "test_final_pred.drop('probability', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>repeatProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18470775</td>\n",
       "      <td>0.235207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86880128</td>\n",
       "      <td>0.242135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87553372</td>\n",
       "      <td>0.226724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98483695</td>\n",
       "      <td>0.254151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101001592</td>\n",
       "      <td>0.258242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  repeatProbability\n",
       "0   18470775           0.235207\n",
       "1   86880128           0.242135\n",
       "2   87553372           0.226724\n",
       "3   98483695           0.254151\n",
       "4  101001592           0.258242"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151484.000000\n",
       "mean          0.252107\n",
       "std           0.017777\n",
       "min           0.170819\n",
       "25%           0.250102\n",
       "50%           0.254151\n",
       "75%           0.254151\n",
       "max           0.447843\n",
       "Name: repeatProbability, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_pred['repeatProbability'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the test file to csv\n",
    "#test_final_pred.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
